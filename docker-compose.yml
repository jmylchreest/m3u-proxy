version: "3.8"

# networks:
#   m3u-proxy-net:
#     driver: bridge
#     enable_ipv6: true
#     ipam:
#       driver: default
#       config:
#         - subnet: 172.20.0.0/16
#         - subnet: fd00::/64

services:
  postgres:
    image: postgres:latest
    # networks:
    #   - m3u-proxy-net
    env_file: .env
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT:-5432}:5432" # Optional: expose for external access
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${POSTGRES_USER:-m3u_proxy} -d ${POSTGRES_DB:-m3u_proxy}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  m3u-proxy:
    image: ghcr.io/jmylchreest/m3u-proxy:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    # networks:
    #   - m3u-proxy-net
    ports:
      - "${M3U_PROXY_PORT:-8080}:8080"
    env_file: .env

    volumes:
      - m3u_data:/app/data

      # Optional: Mount configuration directory
      # - ./config:/app/config

    # Hardware acceleration support for FFmpeg transcoding
    devices:
      - /dev/dri:/dev/dri  # Intel/AMD GPU hardware acceleration
    group_add:
      - video              # Video group access for hardware devices
    
    restart: unless-stopped

    # Optional: Add resource limits
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

    # Health check using internal container address
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:8080/api/v1/sources"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    profiles:
      - observability
    command:
      - --config=/etc/otelcol-contrib/otel-collector.yml
    volumes:
      - ./observability/otel-collector.yml:/etc/otelcol-contrib/otel-collector.yml
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics
      - "8889:8889"   # Prometheus metrics
    depends_on:
      - tempo
      - loki
      - mimir

  # Tempo - Distributed Tracing
  tempo:
    image: grafana/tempo:latest
    profiles:
      - observability
    command:
      - -config.file=/etc/tempo.yaml
    volumes:
      - ./observability/tempo.yml:/etc/tempo.yaml
      - tempo_data:/tmp/tempo
    ports:
      - "3200:3200"   # Tempo

  # Loki - Log Aggregation
  loki:
    image: grafana/loki:latest
    profiles:
      - observability
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./observability/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    ports:
      - "3100:3100"

  # Mimir - Metrics Storage
  mimir:
    image: grafana/mimir:latest
    profiles:
      - observability
    command:
      - -config.file=/etc/mimir.yaml
    volumes:
      - ./observability/mimir.yml:/etc/mimir.yaml
      - mimir_data:/data
    ports:
      - "9009:9009"

  # Grafana - Observability Dashboard
  grafana:
    image: grafana/grafana:latest
    profiles:
      - observability
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./observability/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      - tempo
      - loki
      - mimir

volumes:
  m3u_data:
    driver: local
  postgres_data:
    driver: local
  # Observability volumes
  tempo_data:
    driver: local
  loki_data:
    driver: local
  mimir_data:
    driver: local
  grafana_data:
    driver: local
